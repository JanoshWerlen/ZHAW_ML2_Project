{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goal and Motivation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of the project stems from the problem that legal documents are large in size and interwoven.   \n",
    "Oftentimes, questions are hard to link to the right and relevant articles.   \n",
    "One reason for this is that titles of articles are often not precise enough for the average person to find the answers they need.   \n",
    "Furthermore, it usually takes a lot of time to find the right content,   \n",
    "especially when multiple legal documents are connected and therefore need to be consulted together.  \n",
    "\n",
    "The goal of this project, therefore, is to create a RAG-Bot that can take user inputs in the form of a legal question and return relevant articles and provide responses that can help the user continue their research.   \n",
    "It is important to state that AI itself should NOT be used to provide legally binding responses. So the response should only be seen as a way to find the most relevant legal texts that should be consulted by the users themselves.  \n",
    "\n",
    "My personal motivation derives from my employment in HR, where many employees are very unfamiliar with the legal bases they need to adhere to.   \n",
    "Also, many of the employees within HR need to dedicate time to find the right legal groundwork when responding to questions posed by other employees.   \n",
    "This bot can help reduce the research time by finding and providing relevant articles that correspond to the question at hand.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My RAG bot uses multiple Documents as basis to provide relevant answers. \n",
    "These documents are:   \n",
    "    -Personalrecht der Stadt Zürich incl. Ausführungsbestimmungen  \n",
    "    -Arbeitsgesetz der Schweiz  \n",
    "    -Kaderärztereglement des Stadtspitals Zürich  \n",
    "    -Pausenreglement des Stadtspitals Zürich  \n",
    "    -Pikettreglement des Stadtspitals Zürich  \n",
    "    -Regelement zum Bereitschaftsdienst des Stadtspitals Zürich  \n",
    "    -Gesamtspitalweisung für Oberärzte*innen des Stadtspitals Zürich  \n",
    "\n",
    "\n",
    "# Approach 1: PDF Embedding and Chroma_db:\n",
    "\n",
    "All data are originally PDF documents. At first, I tried to perform my request using a \"standard\" RAG embedding/retrieval. Therefore, I used the whole PDF and split/embedded them.\n",
    "\n",
    "Here is an example for the search query \"Was sind Nachtzulagen\":\n",
    "\n",
    "![image.png](img/PR_embedding_whole_pdf.png)\n",
    "\n",
    "The result seemed promising, even though not really surprising as articles usually don't have much overlapping content and articles focus on individual topics. The problems arose when looking at the actual responses retrieved by the RAG request:\n",
    "\n",
    "\n",
    "Extarct of the Result on the request \"Was sind Nachtzulagen\" \n",
    "*******************************************************\n",
    "\n",
    "\n",
    "Chunk ID: 421, Content: 62 89, 91, 92 \n",
    "Treueprämie: Berechnung 13, 62 88, 91, 191 \n",
    "Treueprämie: Teilprämie  90 \n",
    " 223 Schlagwort PR Art. AB PR Art. \n",
    "Treueurlaub  135 \n",
    "U   \n",
    "Überbrückungszuschuss 27  \n",
    "Übergangsbestimmungen 89 187ff \n",
    "Überleitung 89 187, 188 \n",
    "Überstunden → siehe Überzeit   \n",
    "Überwachung  55 \n",
    "Überzeit: Barvergütung von \n",
    "Mahlzeiten  109 \n",
    "Überzeit: Grundsätze  162, 167, \n",
    "173 \n",
    "\n",
    "Chunk ID: 207, Content: passen. \n",
    "Art. 177 Abweichende Zuschläge für Nacht- und  \n",
    "Sonntagsarbeit \n",
    "Von Art. 176 abweichende Stunden zuschläge gelten aufgrund \n",
    "der besonderen Arbeitszeiten für die folgenden Personalgrup-\n",
    "pen: \n",
    "a)  Vereinsabwartinnen und -abw arte, Badaufsichten, Spette-\n",
    "rinnen und Spetter der Abte ilung Anlagen und Schulsport \n",
    "des Sportamtes: Zuschlag für Sonn- und Feiertagsdienste Fr. 4.20 je Stunde, kein Zuschlag für Nachtdienst; \n",
    "b)  Tätigkeit als Abend- un d Wochenendsupporterin oder \n",
    "-supporter im Ausbildungsz entrum von Schutz und Rettung \n",
    "Zürich: Zuschlag für Sonn- und Feiertagsdienste Fr. 4.20 je Stunde, kein Zuschlag für Nachtdienst; \n",
    "c)  Aufsichtspersonal im Museum Rietberg, Strauhof und \n",
    "Helmhaus: Zuschlag für Nacht-, Sonn- und Feiertagsdienst Fr. 4.20 je Stunde. \n",
    "Ausführungsbestimmungen zum Personalrecht  \n",
    " 107 Art. 178 Zeitkompensation für Nachtdienst \n",
    "1Die Angestellten, mit Ausnahme der Ärztinnen und Ärzte und \n",
    "derjenigen Angestellten der Verkehr sbetriebe, die dem Arbeits-\n",
    "zeitges\n",
    "Chunk ID: 0, Content: 177.100 \n",
    "177.101 \n",
    " \n",
    " \n",
    "  \n",
    "Personalrecht\n",
    "Verordnung\n",
    "über das Arbeitsverhältnis\n",
    "des städtischen Personals und\n",
    "Ausführungsbestimmungen\n",
    "Gültig ab 1. Juli 2002\n",
    "Nachgeführt bis 7. Februar 2007\n",
    " \n",
    " \n",
    "  \n",
    " I Verordnung über das Arbei tsverhältnis des städtischen \n",
    "Personals (Personalrecht) \n",
    " \n",
    "Titelverzeichnis  \n",
    "Titel  Artikel PR Seite \n",
    "I. Allgemeine Bestimmungen  1 - 4 1 \n",
    " A. Geltungsbereich 1 1 \n",
    " B. Begriffe 2 2 \n",
    " C. Personalpolitik 3 – 3bis 2 \n",
    "Personalverbände 70, 71, 74 10, 131, \n",
    "143, 144, \n",
    "147 \n",
    "Personalvermittlung  16 \n",
    "Personalvorschriften  21 \n",
    "Personendaten 42ff 17, 44ff \n",
    "Persönlichkeitsschutz 20, 68 96, 150 \n",
    "Pflege kranker  Familienmitglieder  129 \n",
    "Pflegekindverhältnis  128, 130 \n",
    "Pflichten der Angestellten 77ff 149ff \n",
    " 219 Schlagwort PR Art. AB PR Art. \n",
    "Pikettdienst  172, 173 \n",
    "Polizeilicher Führungsbericht  19 \n",
    "Praktikum 12  \n",
    "Prämien 59 68, 148 \n",
    "Praxisberatung  11 \n",
    "Private Abwesenheiten  161 \n",
    "Probezeit 14 29, 122 \n",
    "Prozesskosten 36 42 \n",
    "Q   \n",
    "Qualitätszirkel 76  \n",
    "R   \n",
    "Recht auf Begründung 17, 38  \n",
    "Recht auf Berichtigung 45 19, 49, 142 \n",
    "Recht auf Einsicht/Auskunft 45, 46 19, 47 ,48 \n",
    "Rechte der Angestellten 68ff 96ff \n",
    "Rechtliches Gehör 37 19, 34 \n",
    "Rechtsmittel 39  \n",
    "Rechtsmittelbelehrung 17, 38  \n",
    "Rechtsschutz 36 42 \n",
    "Referenzauskunft  17, 51 \n",
    "Regelarbeitszeit  157 \n",
    "Reintegration  9 \n",
    "Rekurs 39  \n",
    "Reorganisation  16 \n",
    "Rotkreuzdienst  126 \n",
    "220 Schlagwort PR Art. AB PR Art. \n",
    "Ruhetage 81 58, 73, 157, \n",
    "169 \n",
    "Ruhezeit  123, 167, \n",
    "178 \n",
    "S \n",
    "Chunk ID: 27, Content: chutzbeau ftragte oder den Datenschutzbe-\n",
    "auftragten, die Stadtamtsfrauen und Stadtammänner, Friedens-\n",
    "richterinnen und Friedensricht er, Schulpräsidentinnen und \n",
    "Schulpräsidenten gilt das Persona lrecht sinngemäss, soweit \n",
    "nicht besondere Best immungen bestehen. \n",
    "Personalrecht  \n",
    "2 B. Begriffe \n",
    "Art. 2 Angestellte; Anstellungsinstanz  \n",
    "1Angestellte sind Personen, die unb efristet oder befristet mit ei-\n",
    "nem vollen oder teilweisen Pensum  im städtischen Dienst ste-\n",
    "hen. \n",
    "\n",
    "******************************************\n",
    "Even though the response was not completely wrong given the returned response of Article 177., yet it was evident that splitting legal documents created a problem. Articles are self-contained pieces of information that need to be considered independently of each other but also in full. So giving this response to an LM would yield limited results.\n",
    "\n",
    "Additionally, there was a second problem. Combining different articles together led to a situation where sometimes the question would be part of multiple articles originating from different legal bases. Depending on the circumstances, only some of the articles are relevant, and therefore only those should be returned to the user and processed by the LM to provide the best possible result.\n",
    "\n",
    "By combining the documents in different versions, this could reduce the problem. This led to a situation where I had to use multiple embeddings and vector stores, then only retrieve the one relevant to the question and situation.\n",
    "\n",
    "While complicating things, it turned out to work to some capacity. In the end, I abandoned this approach as I was unable to reliably filter articles as a whole to provide to the LM for further processing.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Version of the project can be found in the following github repo: https://github.com/JanoshWerlen/RAG_Bot_STZ\n",
    "it can be run using \"python app.py\" and accessing the Interface via a Browser. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approach 2: using JSON\n",
    "\n",
    "In my second atempt i decided that the data i am working with needs to be handeled differently and preprocessed before beeing able to yield good results. \n",
    "\n",
    "So i decided to parse all the Articles into JSON and embedd them in whole.  \n",
    "As all original docuements are formatted differently and also vary in machine-readability i parsed them using GPT-4o,   \n",
    "promting it to parse the articles into the given JSON format. \n",
    "\n",
    "The result can be found here: [data/1_documents_json](App/data/1_documents_json/)\n",
    "\n",
    "\n",
    "I then used two differen models to embedd the individual documents as well as combinations of parsed articles into groups that represent the relevant legal grounds for the different groups i decided to implement in my bot.\n",
    "  \n",
    "Groups:  \n",
    "    - Nicht-Ärztliches Personal   \n",
    "    - Assistenzärzte  \n",
    "    - Ärztliches Personal excl. Assistenzärzte  \n",
    "    - Wildcard / Alle Artikel kombiniert.   \n",
    "\n",
    "The combinations of these groups were then embedded using the following code: \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "import numpy as np\n",
    "import faiss\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "\n",
    "def get_embedding(text, tags, type, model=\"text-embedding-3-large\"):\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "    combine = text + \" \" .join(tags) + \" \" .join(type)\n",
    "    return openai.embeddings.create(input=[combine], model=model).data[0].embedding\n",
    "\n",
    "def load_json(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        return json.load(file)\n",
    "\n",
    "def save_json(data, file_path):\n",
    "    with open(file_path, 'w', encoding='utf-8') as file:\n",
    "        json.dump(data, file, indent=4, ensure_ascii=False)\n",
    "\n",
    "file_path = 'APP/data/KAR/KAR.json'\n",
    "data = load_json(file_path)\n",
    "file_path_new = 'APP/data/KAR/KAR_embedded.json'\n",
    "\n",
    "for article in data:\n",
    "    article_text = article['text']\n",
    "    article_tags = article['metadata']['tags']\n",
    "    article_type = article['metadata']['type']\n",
    "    article['embedding'] = get_embedding(article_text, article_tags, article_type)\n",
    "\n",
    "save_json(data, file_path_new)\n",
    "\n",
    "embeddings = np.array([article['embedding'] for article in data]).astype('float32')\n",
    "\n",
    "base_index = faiss.IndexFlatL2(embeddings.shape[1])\n",
    "\n",
    "index = faiss.IndexIDMap(base_index)\n",
    "\n",
    "# IDs for the articles\n",
    "ids = np.array([i for i in range(len(data))], dtype='int64')\n",
    "\n",
    "# Add vectors and their IDs to the index\n",
    "index.add_with_ids(embeddings, ids)\n",
    "\n",
    "# Save the index to disk\n",
    "faiss.write_index(index, \"APP/data/KAR/KAR.index\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The embedded results can be viewed here: [Embeddings](App\\data\\2_embedded)  \n",
    "Now that I had different embeddings of different combinations of legal documents, I evaluated them on how well the returned relevant and similar results.\n",
    "\n",
    "# Evaluation\n",
    "\n",
    "The evaluations can be found here: [Evaluation](Evaluate.ipynb)  \n",
    "The results were promising. Evaluating the results of the same query over different versions of embeddings yielded good results. The returned articles were relevant given a relevant user input.\n",
    "\n",
    "One exaple is the result here given the input \"Was sind die Pausenregelungen?\"  \n",
    "that was improved to :  \n",
    "\"Was sind die gesetzlich vorgeschriebenen Pausenregelungen für Angestellte am Stadtspital Zürich in der Schweiz?  \n",
    "Wie sind die Arbeitszeiten und Pausen am Stadtspital Zürich in der Schweiz geregelt?  \n",
    "Gibt es spezifische Regelungen für Mindestpausen und Ruhezeiten für Arbeitnehmer am Stadtspital Zürich in der Schweiz?  \n",
    "Welche Vorschriften gelten bezüglich Pausenregelungen für Mitarbeiter des Stadtspitals Zürich in der Schweiz?  \n",
    "Welche Pausenregelungen müssen gemäß schweizerischem Arbeitsrecht am Stadtspital Zürich eingehalten werden?\"    \n",
    "by an impovment LM function :  \n",
    "![image.png](img\\PR_embedding_json.png)\n",
    " \n",
    "\n",
    " Here we can see that one of the top results:  \n",
    " Article ID: 284 PReg, Pausenregelung für Assistenzärztinnen und -ärzte  \n",
    " should not the relevant here, as this combination of articles is not intended to be used for Assistenzärzt. So I filtered my Articles and removed all irrlevant Articles that were still in my data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
